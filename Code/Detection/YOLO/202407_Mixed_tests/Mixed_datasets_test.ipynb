{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Praperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jpan/xAI_Masterthesis_Pan/Code/Detection/YOLO/202407_Mixed_tests\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLEARML_WEB_HOST=https://app.clear.ml\n",
      "env: CLEARML_API_HOST=https://api.clear.ml\n",
      "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
      "env: CLEARML_API_ACCESS_KEY=Z4YDBU13VPOFHBHF8667\n",
      "env: CLEARML_API_SECRET_KEY=JMzvRXn76AT83WuFJfS0FBGCY8c5TccbH5XboTYztrWqwzDdyn\n"
     ]
    }
   ],
   "source": [
    "#clearml mac\n",
    "# %env CLEARML_WEB_HOST=https://app.clear.ml\n",
    "# %env CLEARML_API_HOST=https://api.clear.ml\n",
    "# %env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "# %env CLEARML_API_ACCESS_KEY=QO1VBBX9J2S2VYILQTGI\n",
    "# %env CLEARML_API_SECRET_KEY=ERuc1S6o5SirQGugvYXDFjH9b9aNi0u8S3rpALzXMa8YPSLDMW\n",
    "\n",
    "# clearml win\n",
    "%env CLEARML_WEB_HOST=https://app.clear.ml\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=Z4YDBU13VPOFHBHF8667\n",
    "%env CLEARML_API_SECRET_KEY=JMzvRXn76AT83WuFJfS0FBGCY8c5TccbH5XboTYztrWqwzDdyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.41 ðŸš€ Python-3.12.2 torch-2.3.1+cu121 CUDA:0 (NVIDIA RTX A5000, 24241MiB)\n",
      "Setup complete âœ… (24 CPUs, 125.5 GB RAM, 320.5/459.6 GB disk)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpan/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "# Pip install method (recommended)\n",
    "\n",
    "!pip install ultralytics\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'project': 'Uni-Wood', 'name': 'Mixed_YOLO_all_test_1', 'exist_ok': False, 'data_server': '/mnt/data/backup_pan/Dataset/Mixed_datasets/Det-dominik_v_1-v2-sf_v1.v2i.yolov8', 'data_yaml': '/mnt/data/backup_pan/Dataset/Mixed_datasets/Det-dominik_v_1-v2-sf_v1.v2i.yolov8/data.yaml', 'test_data': '/path/to/test_data.txt', 'imgsz': 640, 'model': 'yolov10m.yaml', 'task': 'detect', 'mode': 'train', 'device_mac': 'mps', 'device_win': 0, 'epochs': 1, 'batch': 16, 'lr0': 0.001, 'cos_lr': True, 'weight_decay': 0.0005, 'dropout': 0.0, 'optimizer': 'Adam', 'momentum': 0.9, 'seed': 42, 'save': False, 'save_period': -1, 'plots': True, 'test_output': '/path/to/test_output'}\n"
     ]
    }
   ],
   "source": [
    "# read config file\n",
    "import yaml\n",
    "\n",
    "def load_config(config_file):\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "config = load_config('Mixed_all_config_1.yaml')\n",
    "\n",
    "print(config)\n",
    "\n",
    "# project\n",
    "project = config['project']\n",
    "name = config['name']\n",
    "exist_ok = config['exist_ok']\n",
    "\n",
    "# dataset\n",
    "data_folder = config['data_server']\n",
    "data = config['data_yaml']\n",
    "test_data = config['test_data']\n",
    "imgsz = config['imgsz']\n",
    "\n",
    "# model\n",
    "model = config['model']\n",
    "task = config['task']\n",
    "mode = config['mode']\n",
    "# device = config['device_mac']\n",
    "device = config['device_win']\n",
    "\n",
    "# Training parameters\n",
    "epochs = config['epochs']\n",
    "batch = config['batch']\n",
    "lr0 = config['lr0']\n",
    "cos_lr = config['cos_lr']\n",
    "weight_decay = config['weight_decay']\n",
    "dropout = config['dropout']\n",
    "optimizer = config['optimizer']\n",
    "momentum = config['momentum']\n",
    "seed = config['seed']\n",
    "\n",
    "# Output configuration\n",
    "# save = config['save']\n",
    "# save_period = config['save_period']\n",
    "plots = config['plots']\n",
    "test_output = config['test_output']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "train_dir = os.path.join(data_folder, \"train\")\n",
    "val_dir = os.path.join(data_folder, \"valid\")\n",
    "test_dir = os.path.join(data_folder, \"test\")\n",
    "\n",
    "os.makedirs(os.path.join(val_dir, \"images\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(val_dir, \"labels\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_dir, \"images\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_dir, \"labels\"), exist_ok=True)\n",
    "\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.05\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "image_files = os.listdir(os.path.join(train_dir, \"images\"))\n",
    "label_files = os.listdir(os.path.join(train_dir, \"labels\"))\n",
    "\n",
    "image_files.sort()\n",
    "label_files.sort()\n",
    "\n",
    "data_pairs = list(zip(image_files, label_files))\n",
    "\n",
    "random.shuffle(data_pairs)\n",
    "\n",
    "total_files = len(data_pairs)\n",
    "val_count = int(total_files * val_ratio)\n",
    "test_count = int(total_files * test_ratio)\n",
    "\n",
    "val_data = data_pairs[:val_count]\n",
    "test_data = data_pairs[val_count:val_count+test_count]\n",
    "train_data = data_pairs[val_count+test_count:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files(data, src_dir, dest_dir):\n",
    "    for img_file, lbl_file in data:\n",
    "        shutil.move(os.path.join(src_dir, \"images\", img_file), os.path.join(dest_dir, \"images\", img_file))\n",
    "        shutil.move(os.path.join(src_dir, \"labels\", lbl_file), os.path.join(dest_dir, \"labels\", lbl_file))\n",
    "\n",
    "move_files(val_data, train_dir, val_dir)\n",
    "move_files(test_data, train_dir, test_dir)\n",
    "\n",
    "print(\"Split done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files(directory):\n",
    "    images_count = len(os.listdir(os.path.join(directory, \"images\")))\n",
    "    labels_count = len(os.listdir(os.path.join(directory, \"labels\")))\n",
    "    return images_count, labels_count\n",
    "\n",
    "train_images_count, train_labels_count = count_files(train_dir)\n",
    "val_images_count, val_labels_count = count_files(val_dir)\n",
    "test_images_count, test_labels_count = count_files(test_dir)\n",
    "\n",
    "print(f\"Train set: {train_images_count} images, {train_labels_count} labels\")\n",
    "print(f\"Validation set: {val_images_count} images, {val_labels_count} labels\")\n",
    "print(f\"Test set: {test_images_count} images, {test_labels_count} labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_back_files(src_dir, dest_dir):\n",
    "    for file_name in os.listdir(os.path.join(src_dir, \"images\")):\n",
    "        shutil.move(os.path.join(src_dir, \"images\", file_name), os.path.join(dest_dir, \"images\", file_name))\n",
    "    for file_name in os.listdir(os.path.join(src_dir, \"labels\")):\n",
    "        shutil.move(os.path.join(src_dir, \"labels\", file_name), os.path.join(dest_dir, \"labels\", file_name))\n",
    "\n",
    "move_back_files(val_dir, train_dir)\n",
    "move_back_files(test_dir, train_dir)\n",
    "\n",
    "print(\"Recovered!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clearml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=93791013d21249788478a2f39c080d63\n",
      "2024-07-17 11:21:56,624 - clearml.Task - INFO - Storing jupyter notebook directly as code\n"
     ]
    }
   ],
   "source": [
    "from clearml import Task\n",
    "\n",
    "#Clear ML Initialization\n",
    "cl_task = Task.init(project_name=project,task_name=name)\n",
    "logger = cl_task.get_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(model)\n",
    "\n",
    "results = model.train(project=project, name=name, exist_ok=exist_ok, data=data, imgsz=imgsz, task=task, device=device, epochs=epochs, batch=batch, lr0=lr0, cos_lr=cos_lr, weight_decay=weight_decay, dropout=dropout, optimizer=optimizer, momentum=momentum, seed=seed, plots=plots)\n",
    "\n",
    "cl_task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "model_path = \"/Users/holmes/Documents/UNI-Bamberg/Arbeiten/Uni_Bamberg_KDWT_Holzprojekt/Project_process/P2_Experiments/202403_Schweinfurt/Uni-Wood/Schweinfurt-Yolo-Test-4/weights/best.pt\"\n",
    "\n",
    "image_folder = \"/Users/holmes/Desktop/probe\"\n",
    "\n",
    "save_path = \"/Users/holmes/Desktop/probe\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images\n",
    "resized_image_folder = os.path.join(image_folder, \"resized\")\n",
    "os.makedirs(resized_image_folder, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(image_folder):\n",
    "    if file.endswith(('.jpg', '.JPG', '.jpeg', '.png', '.bmp')):\n",
    "        img_path = os.path.join(image_folder, file)\n",
    "        img = cv2.imread(img_path)\n",
    "        img_resized = cv2.resize(img, (640, 640))\n",
    "        resized_img_path = os.path.join(resized_image_folder, os.path.splitext(file)[0] + \"_resize\" + os.path.splitext(file)[1])\n",
    "        cv2.imwrite(resized_img_path, img_resized)\n",
    "image_folder = resized_image_folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(model_path)\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "image_files = [os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith(('.jpg', '.jpeg', '.JPG', '.png', '.bmp'))]\n",
    "\n",
    "for img_path in image_files:\n",
    "    results = model(img_path)\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes.cpu().numpy()\n",
    "        for box in boxes:\n",
    "            # box contains prediction information\n",
    "            confidence = box.conf[0]\n",
    "            if confidence > 0.4:\n",
    "                xyxy = box.xyxy[0].astype(int)\n",
    "                confidence_text = f\"{confidence:.2f}\"\n",
    "\n",
    "                cv2.rectangle(img, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), (0, 0, 255), 2)\n",
    "                cv2.putText(img, confidence_text, (xyxy[0], xyxy[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "    unique_save_path = os.path.join(save_path, os.path.basename(img_path))\n",
    "    cv2.imwrite(unique_save_path, img)\n",
    "    print(f\"Image saved: {unique_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

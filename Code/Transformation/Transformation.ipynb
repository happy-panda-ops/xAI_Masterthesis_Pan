{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read image and segmented area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_name': '/mnt/data/backup_pan/Dataset/Seg-dominik-iphone/Dominik-seg.v4i.coco-segmentation/valid/Model_2_0070_jpeg.rf.f6b63d3d61757bb631819d5e228ffe1f.jpg', 'instances': [{'class': 1, 'box': [275.2068176269531, 0.0, 562.5582275390625, 1024.0], 'score': 0.9998154044151306, 'mask': [{'polygon': [[321, 0], [319, 2], [318, 2], [312, 8], [312, 9], [311, 10], [311, 11], [310, 12], [310, 15], [309, 16], [309, 22], [308, 23], [308, 38], [307, 39], [307, 72], [306, 73], [306, 217], [305, 218], [305, 279], [304, 280], [304, 296], [303, 297], [303, 309], [302, 310], [302, 315], [301, 316], [301, 320], [300, 321], [300, 326], [299, 327], [299, 333], [298, 334], [298, 343], [297, 344], [297, 364], [296, 365], [296, 461], [295, 462], [295, 531], [294, 532], [294, 552], [293, 553], [293, 568], [292, 569], [292, 579], [291, 580], [291, 587], [290, 588], [290, 595], [289, 596], [289, 607], [288, 608], [288, 622], [287, 623], [287, 641], [286, 642], [286, 659], [285, 660], [285, 677], [284, 678], [284, 688], [283, 689], [283, 697], [282, 698], [282, 705], [281, 706], [281, 711], [280, 712], [280, 718], [279, 719], [279, 726], [278, 727], [278, 737], [277, 738], [277, 754], [276, 755], [276, 809], [275, 810], [275, 1006], [276, 1007], [276, 1011], [277, 1012], [277, 1015], [278, 1016], [278, 1018], [279, 1019], [279, 1021], [280, 1022], [281, 1022], [282, 1023], [552, 1023], [553, 1022], [557, 1022], [557, 1021], [558, 1020], [558, 1018], [559, 1017], [559, 1015], [560, 1014], [560, 1011], [561, 1010], [561, 816], [560, 815], [560, 791], [559, 790], [559, 769], [558, 768], [558, 750], [557, 749], [557, 737], [556, 736], [556, 725], [555, 724], [555, 710], [554, 709], [554, 687], [553, 686], [553, 654], [552, 653], [552, 620], [551, 619], [551, 593], [550, 592], [550, 574], [549, 573], [549, 555], [548, 554], [548, 536], [547, 535], [547, 522], [546, 521], [546, 511], [545, 510], [545, 499], [544, 498], [544, 482], [543, 481], [543, 462], [542, 461], [542, 441], [541, 440], [541, 410], [540, 409], [540, 359], [539, 358], [539, 331], [540, 330], [540, 242], [541, 241], [541, 137], [540, 136], [540, 91], [541, 90], [541, 66], [542, 65], [542, 22], [541, 21], [541, 15], [540, 14], [540, 12], [539, 11], [539, 9], [538, 8], [538, 7], [537, 6], [537, 5], [535, 3], [533, 3], [532, 2], [530, 2], [529, 1], [527, 1], [526, 0]]}]}, {'class': 2, 'box': [537.1096801757812, 10.719648361206055, 687.4585571289062, 1024.0], 'score': 0.9995890259742737, 'mask': [{'polygon': [[550, 11], [545, 16], [545, 18], [544, 19], [544, 23], [543, 24], [543, 55], [544, 56], [544, 80], [545, 81], [545, 95], [546, 96], [546, 118], [547, 119], [547, 183], [548, 184], [548, 337], [549, 338], [549, 390], [550, 391], [550, 403], [551, 404], [551, 415], [552, 416], [552, 435], [553, 436], [553, 465], [554, 466], [554, 487], [555, 488], [555, 504], [556, 505], [556, 518], [557, 519], [557, 536], [558, 537], [558, 558], [559, 559], [559, 582], [560, 583], [560, 603], [561, 604], [561, 620], [562, 621], [562, 644], [563, 645], [563, 676], [564, 677], [564, 741], [565, 742], [565, 770], [566, 771], [566, 787], [567, 788], [567, 801], [568, 802], [568, 819], [569, 820], [569, 854], [570, 855], [570, 881], [571, 882], [571, 898], [572, 899], [572, 919], [573, 920], [573, 961], [574, 962], [574, 1009], [575, 1010], [575, 1014], [576, 1015], [576, 1018], [577, 1019], [577, 1020], [578, 1021], [579, 1021], [580, 1022], [581, 1022], [582, 1023], [679, 1023], [684, 1018], [684, 1015], [685, 1014], [685, 1007], [686, 1006], [686, 973], [685, 972], [685, 956], [684, 955], [684, 946], [683, 945], [683, 935], [682, 934], [682, 908], [681, 907], [681, 857], [680, 856], [680, 842], [679, 841], [679, 833], [678, 832], [678, 824], [677, 823], [677, 812], [676, 811], [676, 798], [675, 797], [675, 785], [674, 784], [674, 777], [673, 776], [673, 771], [672, 770], [672, 762], [671, 761], [671, 748], [670, 747], [670, 730], [669, 729], [669, 716], [668, 715], [668, 708], [667, 707], [667, 701], [666, 700], [666, 690], [665, 689], [665, 674], [664, 673], [664, 661], [663, 660], [663, 652], [662, 651], [662, 644], [661, 643], [661, 630], [660, 629], [660, 610], [659, 609], [659, 585], [658, 584], [658, 570], [657, 569], [657, 563], [656, 562], [656, 556], [655, 555], [655, 547], [654, 546], [654, 535], [653, 534], [653, 527], [652, 526], [652, 522], [651, 521], [651, 517], [650, 516], [650, 510], [649, 509], [649, 500], [648, 499], [648, 490], [647, 489], [647, 484], [646, 483], [646, 480], [645, 479], [645, 475], [644, 474], [644, 467], [643, 466], [643, 454], [642, 453], [642, 442], [641, 441], [641, 433], [640, 432], [640, 421], [639, 420], [639, 400], [638, 399], [638, 369], [637, 368], [637, 349], [636, 348], [636, 339], [635, 338], [635, 330], [634, 329], [634, 313], [633, 312], [633, 275], [632, 274], [632, 251], [631, 250], [631, 229], [630, 228], [630, 210], [629, 209], [629, 195], [628, 194], [628, 172], [627, 171], [627, 143], [626, 142], [626, 128], [625, 127], [625, 118], [624, 117], [624, 108], [623, 107], [623, 85], [622, 84], [622, 59], [621, 58], [621, 44], [620, 43], [620, 34], [619, 33], [619, 26], [618, 25], [618, 21], [617, 20], [617, 18], [616, 17], [616, 15], [615, 14], [615, 13], [614, 12], [613, 12], [612, 11]]}]}]}\n"
     ]
    }
   ],
   "source": [
    "image_org = cv2.imread(\"/Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Transformation/Model_2_0070_jpeg.rf.f6b63d3d61757bb631819d5e228ffe1f.jpg\")\n",
    "image_seg = cv2.imread(\"/Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Transformation/test_Model_2_0070_jpeg.rf.f6b63d3d61757bb631819d5e228ffe1f.jpg\")\n",
    "\n",
    "# read json file\n",
    "with open(\"/Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Transformation/test_Model_2_0070_jpeg.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "seg_output = data\n",
    "class_map = {1: \"other\", 2: \"main_beam\"}\n",
    "\n",
    "print(seg_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select main area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select max area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate area of polygon from given points\n",
    "def calculate_area(points_polygon):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select main beam area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_main_area(segmentation_output, category_name_map):\n",
    "    instances = segmentation_output[\"instances\"]\n",
    "    masks = instances[\"pred_masks\"]\n",
    "    classes = instances[\"pred_classes\"]\n",
    "\n",
    "    # max area index\n",
    "    areas = masks.sum(dim=(1, 2))\n",
    "    max_area_index = areas.argmax().item()\n",
    "    \n",
    "    # main_beam class index\n",
    "    main_beam_indices = [i for i, cls in enumerate(classes) if category_name_map[cls.item()] == \"main_beam\"]\n",
    "    if main_beam_indices:\n",
    "        main_beam_areas = areas[main_beam_indices]\n",
    "        main_beam_index = main_beam_indices[main_beam_areas.argmax().item()]\n",
    "    else:\n",
    "        main_beam_index = max_area_index\n",
    "\n",
    "    # compare the size of the max area and the main beam area\n",
    "    if areas[max_area_index] > areas[main_beam_index]:\n",
    "        selected_index = max_area_index\n",
    "    else:\n",
    "        selected_index = main_beam_index\n",
    "\n",
    "    return masks[selected_index]\n",
    "\n",
    "selected_mask = select_main_area(segmentation_output, category_name_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract complex polygon from the main area to simple polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_contours(mask, epsilon_factor=0.01):\n",
    "    # get contours\n",
    "    mask_np = mask.cpu().numpy().astype(np.uint8)\n",
    "    contours, _ = cv2.findContours(mask_np, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # simplify contours\n",
    "    simplified_contours = []\n",
    "    for contour in contours:\n",
    "        epsilon = epsilon_factor * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        simplified_contours.append(approx)\n",
    "    \n",
    "    return simplified_contours\n",
    "\n",
    "simplified_contours = simplify_contours(selected_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape the simple polygon to parallel pairs/correct perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m     transformed_contour \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mperspectiveTransform(np\u001b[38;5;241m.\u001b[39marray([contour], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32), M)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transformed_image, transformed_contour\n\u001b[0;32m---> 34\u001b[0m transformed_image, transformed_contour \u001b[38;5;241m=\u001b[39m perspective_transform(simplified_contours, image\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[14], line 20\u001b[0m, in \u001b[0;36mperspective_transform\u001b[0;34m(contours, image_shape)\u001b[0m\n\u001b[1;32m     17\u001b[0m remaining_points \u001b[38;5;241m=\u001b[39m [pt \u001b[38;5;28;01mfor\u001b[39;00m pt \u001b[38;5;129;01min\u001b[39;00m contour \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(pt, p1) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(pt, p2)]\n\u001b[1;32m     18\u001b[0m p3, p4 \u001b[38;5;241m=\u001b[39m remaining_points[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m---> 20\u001b[0m src_pts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32([p1, p2, p3, p4])\n\u001b[1;32m     21\u001b[0m width \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(p1 \u001b[38;5;241m-\u001b[39m p2)\n\u001b[1;32m     22\u001b[0m height \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(p3 \u001b[38;5;241m-\u001b[39m p4)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "def perspective_transform(contours, image_shape):\n",
    "    # find the longest edge of the contour\n",
    "    def find_longest_edge(contour):\n",
    "        max_dist = 0\n",
    "        p1, p2 = None, None\n",
    "        for i in range(len(contour)):\n",
    "            for j in range(i+1, len(contour)):\n",
    "                dist = np.linalg.norm(contour[i] - contour[j])\n",
    "                if dist > max_dist:\n",
    "                    max_dist = dist\n",
    "                    p1, p2 = contour[i][0], contour[j][0]\n",
    "        return p1, p2\n",
    "\n",
    "    # get all the points of the contour\n",
    "    contour = contours[0].squeeze()\n",
    "    p1, p2 = find_longest_edge(contour)\n",
    "    remaining_points = [pt for pt in contour if not np.array_equal(pt, p1) and not np.array_equal(pt, p2)]\n",
    "    p3, p4 = remaining_points[:2]\n",
    "    \n",
    "    src_pts = np.float32([p1, p2, p3, p4])\n",
    "    width = np.linalg.norm(p1 - p2)\n",
    "    height = np.linalg.norm(p3 - p4)\n",
    "    dst_pts = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "    \n",
    "    # calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "    transformed_image = cv2.warpPerspective(image, M, (image_shape[1], image_shape[0]), borderValue=(255, 255, 255))\n",
    "    \n",
    "    # apply the transform to the contour\n",
    "    transformed_contour = cv2.perspectiveTransform(np.array([contour], dtype=np.float32), M)[0]\n",
    "\n",
    "    return transformed_image, transformed_contour\n",
    "\n",
    "transformed_image, transformed_contour = perspective_transform(simplified_contours, image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逼近轮廓\n",
    "def myApprox(con, epsilon_factor=0.01):\n",
    "    epsilon = epsilon_factor * cv2.arcLength(con, True)\n",
    "    approx = cv2.approxPolyDP(con, epsilon, True)\n",
    "    return approx\n",
    "\n",
    "# 多边形矫正\n",
    "def Polygon_correction(img):\n",
    "    if len(img.shape) > 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    contours, _ = cv2.findContours(img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    ori_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    ori_h, ori_w = ori_img.shape[:2]\n",
    "    print('ori_w, ori_h:', ori_w, ori_h)\n",
    "\n",
    "    cv2.imshow('binary', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if len(contours) > 0:\n",
    "        cnts = sorted(contours, key=cv2.contourArea, reverse=True)[:2]\n",
    "        docCnt = None\n",
    "\n",
    "        for cnt in cnts:\n",
    "            approx = myApprox(cnt)\n",
    "            if len(approx) >= 4:\n",
    "                docCnt = approx\n",
    "                break\n",
    "\n",
    "        if docCnt is not None:\n",
    "            rect = cv2.minAreaRect(docCnt)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int0(box)\n",
    "\n",
    "            src_points = np.float32(box)\n",
    "            dst_points = np.float32([[0, 0], [0, ori_h - 1], [ori_w - 1, ori_h - 1], [ori_w - 1, 0]])\n",
    "\n",
    "            M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "            result = cv2.warpPerspective(ori_img, M, (ori_w, ori_h))\n",
    "\n",
    "            for point in box:\n",
    "                cv2.circle(result, tuple(point), 5, (0, 255, 0), 2)\n",
    "\n",
    "            print(\"原始点:\", src_points)\n",
    "            print(\"变换后的点：\", dst_points)\n",
    "\n",
    "            cv2.polylines(result, [box], True, (255, 255, 0), 2)\n",
    "            cv2.imshow('result', result)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            return result\n",
    "        else:\n",
    "            return img\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "# 测试代码\n",
    "# img = cv2.imread('your_image_path_here')\n",
    "# Polygon_correction(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def export_results(original_image, transformed_image, transformed_contour):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # # show the original image\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.title(\"Original Image\")\n",
    "    # plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # # show the transformed image\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.title(\"Transformed Image\")\n",
    "    # plt.imshow(cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # plot the contour\n",
    "    for pt in transformed_contour:\n",
    "        plt.scatter(pt[0], pt[1], c='red')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "export_results(image, transformed_image, transformed_contour)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

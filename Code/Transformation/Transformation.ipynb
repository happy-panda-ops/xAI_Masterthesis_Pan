{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read image and segmented area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread(\"path/to/image.jpg\")\n",
    "\n",
    "image = np.array([\n",
    "    [[255, 0, 0], [0, 255, 0], [0, 0, 255]],        # 红色、绿色、蓝色\n",
    "    [[255, 255, 0], [255, 0, 255], [0, 255, 255]],  # 黄色、紫色、青色\n",
    "    [[255, 255, 255], [128, 128, 128], [0, 0, 0]]   # 白色、灰色、黑色\n",
    "], dtype=np.uint8)\n",
    "\n",
    "\n",
    "segmentation_output = {\n",
    "    \"instances\": {\n",
    "        \"pred_boxes\": (torch.tensor([[10, 10, 100, 100], [20, 20, 200, 200]])),\n",
    "        \"scores\": torch.tensor([0.9, 0.95]),\n",
    "        \"pred_classes\": torch.tensor([1, 2]),\n",
    "        \"pred_masks\": torch.tensor([[[1, 1], [0, 0]], [[1, 1], [1, 1]]]),\n",
    "    },\n",
    "}\n",
    "# input class to category name mapping\n",
    "category_name_map = {1: \"other\", 2: \"main_beam\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select main area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_main_area(segmentation_output, category_name_map):\n",
    "    instances = segmentation_output[\"instances\"]\n",
    "    masks = instances[\"pred_masks\"]\n",
    "    classes = instances[\"pred_classes\"]\n",
    "\n",
    "    # max area index\n",
    "    areas = masks.sum(dim=(1, 2))\n",
    "    max_area_index = areas.argmax().item()\n",
    "    \n",
    "    # main_beam class index\n",
    "    main_beam_indices = [i for i, cls in enumerate(classes) if category_name_map[cls.item()] == \"main_beam\"]\n",
    "    if main_beam_indices:\n",
    "        main_beam_areas = areas[main_beam_indices]\n",
    "        main_beam_index = main_beam_indices[main_beam_areas.argmax().item()]\n",
    "    else:\n",
    "        main_beam_index = max_area_index\n",
    "\n",
    "    # compare the size of the max area and the main beam area\n",
    "    if areas[max_area_index] > areas[main_beam_index]:\n",
    "        selected_index = max_area_index\n",
    "    else:\n",
    "        selected_index = main_beam_index\n",
    "\n",
    "    return masks[selected_index]\n",
    "\n",
    "selected_mask = select_main_area(segmentation_output, category_name_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract complex polygon from the main area to simple polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_contours(mask, epsilon_factor=0.01):\n",
    "    # get contours\n",
    "    mask_np = mask.cpu().numpy().astype(np.uint8)\n",
    "    contours, _ = cv2.findContours(mask_np, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # simplify contours\n",
    "    simplified_contours = []\n",
    "    for contour in contours:\n",
    "        epsilon = epsilon_factor * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        simplified_contours.append(approx)\n",
    "    \n",
    "    return simplified_contours\n",
    "\n",
    "simplified_contours = simplify_contours(selected_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape the simple polygon to parallel pairs/correct perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m     transformed_contour \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mperspectiveTransform(np\u001b[38;5;241m.\u001b[39marray([contour], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32), M)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transformed_image, transformed_contour\n\u001b[0;32m---> 34\u001b[0m transformed_image, transformed_contour \u001b[38;5;241m=\u001b[39m perspective_transform(simplified_contours, image\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[14], line 20\u001b[0m, in \u001b[0;36mperspective_transform\u001b[0;34m(contours, image_shape)\u001b[0m\n\u001b[1;32m     17\u001b[0m remaining_points \u001b[38;5;241m=\u001b[39m [pt \u001b[38;5;28;01mfor\u001b[39;00m pt \u001b[38;5;129;01min\u001b[39;00m contour \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(pt, p1) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(pt, p2)]\n\u001b[1;32m     18\u001b[0m p3, p4 \u001b[38;5;241m=\u001b[39m remaining_points[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m---> 20\u001b[0m src_pts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32([p1, p2, p3, p4])\n\u001b[1;32m     21\u001b[0m width \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(p1 \u001b[38;5;241m-\u001b[39m p2)\n\u001b[1;32m     22\u001b[0m height \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(p3 \u001b[38;5;241m-\u001b[39m p4)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "def perspective_transform(contours, image_shape):\n",
    "    # find the longest edge of the contour\n",
    "    def find_longest_edge(contour):\n",
    "        max_dist = 0\n",
    "        p1, p2 = None, None\n",
    "        for i in range(len(contour)):\n",
    "            for j in range(i+1, len(contour)):\n",
    "                dist = np.linalg.norm(contour[i] - contour[j])\n",
    "                if dist > max_dist:\n",
    "                    max_dist = dist\n",
    "                    p1, p2 = contour[i][0], contour[j][0]\n",
    "        return p1, p2\n",
    "\n",
    "    # get all the points of the contour\n",
    "    contour = contours[0].squeeze()\n",
    "    p1, p2 = find_longest_edge(contour)\n",
    "    remaining_points = [pt for pt in contour if not np.array_equal(pt, p1) and not np.array_equal(pt, p2)]\n",
    "    p3, p4 = remaining_points[:2]\n",
    "    \n",
    "    src_pts = np.float32([p1, p2, p3, p4])\n",
    "    width = np.linalg.norm(p1 - p2)\n",
    "    height = np.linalg.norm(p3 - p4)\n",
    "    dst_pts = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "    \n",
    "    # calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "    transformed_image = cv2.warpPerspective(image, M, (image_shape[1], image_shape[0]), borderValue=(255, 255, 255))\n",
    "    \n",
    "    # apply the transform to the contour\n",
    "    transformed_contour = cv2.perspectiveTransform(np.array([contour], dtype=np.float32), M)[0]\n",
    "\n",
    "    return transformed_image, transformed_contour\n",
    "\n",
    "transformed_image, transformed_contour = perspective_transform(simplified_contours, image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逼近轮廓\n",
    "def myApprox(con, epsilon_factor=0.01):\n",
    "    epsilon = epsilon_factor * cv2.arcLength(con, True)\n",
    "    approx = cv2.approxPolyDP(con, epsilon, True)\n",
    "    return approx\n",
    "\n",
    "# 多边形矫正\n",
    "def Polygon_correction(img):\n",
    "    if len(img.shape) > 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    contours, _ = cv2.findContours(img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    ori_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    ori_h, ori_w = ori_img.shape[:2]\n",
    "    print('ori_w, ori_h:', ori_w, ori_h)\n",
    "\n",
    "    cv2.imshow('binary', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if len(contours) > 0:\n",
    "        cnts = sorted(contours, key=cv2.contourArea, reverse=True)[:2]\n",
    "        docCnt = None\n",
    "\n",
    "        for cnt in cnts:\n",
    "            approx = myApprox(cnt)\n",
    "            if len(approx) >= 4:\n",
    "                docCnt = approx\n",
    "                break\n",
    "\n",
    "        if docCnt is not None:\n",
    "            rect = cv2.minAreaRect(docCnt)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int0(box)\n",
    "\n",
    "            src_points = np.float32(box)\n",
    "            dst_points = np.float32([[0, 0], [0, ori_h - 1], [ori_w - 1, ori_h - 1], [ori_w - 1, 0]])\n",
    "\n",
    "            M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "            result = cv2.warpPerspective(ori_img, M, (ori_w, ori_h))\n",
    "\n",
    "            for point in box:\n",
    "                cv2.circle(result, tuple(point), 5, (0, 255, 0), 2)\n",
    "\n",
    "            print(\"原始点:\", src_points)\n",
    "            print(\"变换后的点：\", dst_points)\n",
    "\n",
    "            cv2.polylines(result, [box], True, (255, 255, 0), 2)\n",
    "            cv2.imshow('result', result)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            return result\n",
    "        else:\n",
    "            return img\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "# 测试代码\n",
    "# img = cv2.imread('your_image_path_here')\n",
    "# Polygon_correction(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def export_results(original_image, transformed_image, transformed_contour):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # # show the original image\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.title(\"Original Image\")\n",
    "    # plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # # show the transformed image\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.title(\"Transformed Image\")\n",
    "    # plt.imshow(cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # plot the contour\n",
    "    for pt in transformed_contour:\n",
    "        plt.scatter(pt[0], pt[1], c='red')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "export_results(image, transformed_image, transformed_contour)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clearml mac\n",
    "# %env CLEARML_WEB_HOST=https://app.clear.ml\n",
    "# %env CLEARML_API_HOST=https://api.clear.ml\n",
    "# %env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "# %env CLEARML_API_ACCESS_KEY=QO1VBBX9J2S2VYILQTGI\n",
    "# %env CLEARML_API_SECRET_KEY=ERuc1S6o5SirQGugvYXDFjH9b9aNi0u8S3rpALzXMa8YPSLDMW\n",
    "\n",
    "# clearml win\n",
    "%env CLEARML_WEB_HOST=https://app.clear.ml\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=Z4YDBU13VPOFHBHF8667\n",
    "%env CLEARML_API_SECRET_KEY=JMzvRXn76AT83WuFJfS0FBGCY8c5TccbH5XboTYztrWqwzDdyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pip install method (recommended)\n",
    "\n",
    "!pip install ultralytics\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config file\n",
    "import yaml\n",
    "\n",
    "def load_config(config_file):\n",
    "    with open(config_file, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "config = load_config('seg_yolo_config_4.yaml')\n",
    "\n",
    "print(config)\n",
    "\n",
    "# project\n",
    "project = config['project']\n",
    "task_name = config['task_name']\n",
    "exist_ok = config['exist_ok']\n",
    "\n",
    "# dataset\n",
    "# data = config['data_mac']\n",
    "data = config['data_win']\n",
    "test_data = config['test_data']\n",
    "imgsz = config['imgsz']\n",
    "\n",
    "# model\n",
    "model = config['model']\n",
    "task = config['task']\n",
    "mode = config['mode']\n",
    "# device = config['device_mac']\n",
    "device = config['device_win']\n",
    "\n",
    "# Training parameters\n",
    "epochs = config['epochs']\n",
    "batch = config['batch']\n",
    "lr0 = config['lr0']\n",
    "cos_lr = config['cos_lr']\n",
    "weight_decay = config['weight_decay']\n",
    "dropout = config['dropout']\n",
    "optimizer = config['optimizer']\n",
    "momentum = config['momentum']\n",
    "seed = config['seed']\n",
    "\n",
    "# Output configuration\n",
    "# save = config['save']\n",
    "# save_period = config['save_period']\n",
    "plots = config['plots']\n",
    "test_output = config['test_output']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "Dataset_version = \"v2\"\n",
    "train_amount = 1113\n",
    "batch_size = batch\n",
    "total_epoch =  epochs\n",
    "base_lr = lr0\n",
    "\n",
    "test_record_csv = \"/home/jpan/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/Test_seg_yolo_record.csv\"\n",
    "\n",
    "# Save in csv\n",
    "new_row = [\n",
    "    task_name,\n",
    "    Dataset_version,\n",
    "    model,\n",
    "    train_amount,\n",
    "    batch_size,\n",
    "    total_epoch,\n",
    "    base_lr,\n",
    "    \"none\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(test_record_csv, header=None)\n",
    "df.loc[len(df)] = new_row\n",
    "\n",
    "df.to_csv(test_record_csv, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clearml\n",
    "from clearml import Task\n",
    "\n",
    "#Clear ML Initialization\n",
    "cl_task = Task.init(project_name=project,task_name=task_name)\n",
    "logger = cl_task.get_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "ini_model = \"/home/jpan/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/yolov8m-seg.pt\"\n",
    "model = YOLO(ini_model)\n",
    "\n",
    "results = model.train(project=project, name=task_name, exist_ok=exist_ok, data=data, imgsz=imgsz, task=task, device=device, epochs=epochs, batch=batch, lr0=lr0, cos_lr=cos_lr, weight_decay=weight_decay, dropout=dropout, optimizer=optimizer, momentum=momentum, seed=seed, plots=plots)\n",
    "\n",
    "cl_task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.45 ðŸš€ Python-3.11.5 torch-2.1.1 CPU (Apple M1 Max)\n",
      "Setup complete âœ… (10 CPUs, 32.0 GB RAM, 868.5/1858.2 GB disk)\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "model_path = \"/Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/weights/best.pt\"\n",
    "\n",
    "image_folder = \"/Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test\"\n",
    "\n",
    "save_path = \"/Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images\n",
    "resized_image_folder = os.path.join(image_folder, \"resized\")\n",
    "os.makedirs(resized_image_folder, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(image_folder):\n",
    "    if file.endswith(('.jpg', '.JPG', '.jpeg', '.png', '.bmp')):\n",
    "        img_path = os.path.join(image_folder, file)\n",
    "        img = cv2.imread(img_path)\n",
    "        img_resized = cv2.resize(img, (640, 640))\n",
    "        resized_img_path = os.path.join(resized_image_folder, os.path.splitext(file)[0] + \"_resize\" + os.path.splitext(file)[1])\n",
    "        cv2.imwrite(resized_img_path, img_resized)\n",
    "image_folder = resized_image_folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/resized/Model_3_0021_jpeg.rf.056041b53706e5d9cea426153674d61d_resize.jpg: 640x640 6 side_beams, 440.6ms\n",
      "Speed: 2.4ms preprocess, 440.6ms inference, 13.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/Model_3_0021_jpeg.rf.056041b53706e5d9cea426153674d61d_resize.jpg\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(model_path)\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "image_files = [os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith(('.jpg', '.jpeg', '.JPG', '.png', '.bmp'))]\n",
    "\n",
    "for img_path in image_files:\n",
    "    results = model.predict(img_path)\n",
    "    colors = [random.choices(range(256), k=3) for _ in classes_ids]\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes.cpu().numpy()\n",
    "        for box in boxes:\n",
    "            # box contains prediction information\n",
    "            confidence = box.conf[0]\n",
    "            if confidence > 0.4:\n",
    "                xyxy = box.xyxy[0].astype(int)\n",
    "                confidence_text = f\"{confidence:.2f}\"\n",
    "\n",
    "                cv2.rectangle(img, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), (0, 0, 255), 2)\n",
    "                cv2.putText(img, confidence_text, (xyxy[0], xyxy[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "    unique_save_path = os.path.join(save_path, os.path.basename(img_path))\n",
    "    cv2.imwrite(unique_save_path, img)\n",
    "    print(f\"Image saved: {unique_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/1_5_resize.png: 640x640 1 main_beam, 3 side_beams, 435.1ms\n",
      "Speed: 1.3ms preprocess, 435.1ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/1_5_resize.png\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/2_3_resize.png: 640x640 1 main_beam, 4 side_beams, 407.5ms\n",
      "Speed: 1.1ms preprocess, 407.5ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/2_3_resize.png\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/Bildexport_3_intensity_resize.jpg: 640x640 11 side_beams, 391.8ms\n",
      "Speed: 0.9ms preprocess, 391.8ms inference, 9.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/Bildexport_3_intensity_resize.jpg\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/4_3_resize.png: 640x640 1 main_beam, 5 side_beams, 396.8ms\n",
      "Speed: 2.1ms preprocess, 396.8ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/4_3_resize.png\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/3_3_resize.png: 640x640 4 side_beams, 413.8ms\n",
      "Speed: 2.1ms preprocess, 413.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/3_3_resize.png\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/4_4_resize.png: 640x640 1 main_beam, 5 side_beams, 406.9ms\n",
      "Speed: 1.0ms preprocess, 406.9ms inference, 5.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/4_4_resize.png\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/3_4_resize.png: 640x640 6 side_beams, 405.3ms\n",
      "Speed: 1.5ms preprocess, 405.3ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/3_4_resize.png\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/2_1_resize.png: 640x640 5 side_beams, 461.0ms\n",
      "Speed: 1.5ms preprocess, 461.0ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/2_1_resize.png\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/2_4_resize.png: 640x640 1 main_beam, 2 side_beams, 409.2ms\n",
      "Speed: 1.3ms preprocess, 409.2ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/2_4_resize.png\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/Bildexport_1_resize.jpg: 640x640 6 side_beams, 408.3ms\n",
      "Speed: 1.4ms preprocess, 408.3ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/Bildexport_1_resize.jpg\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/1_2_resize.png: 640x640 1 main_beam, 5 side_beams, 437.0ms\n",
      "Speed: 1.2ms preprocess, 437.0ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/1_2_resize.png\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/4_1_resize.png: 640x640 1 main_beam, 1 side_beam, 483.1ms\n",
      "Speed: 0.9ms preprocess, 483.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/4_1_resize.png\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/3_1_resize.png: 640x640 5 side_beams, 406.8ms\n",
      "Speed: 1.4ms preprocess, 406.8ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/3_1_resize.png\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/Bildexport_3_color_resize.jpg: 640x640 1 side_beam, 407.2ms\n",
      "Speed: 1.5ms preprocess, 407.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/Bildexport_3_color_resize.jpg\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/Bildexport_2_resize.jpg: 640x640 1 side_beam, 405.4ms\n",
      "Speed: 1.3ms preprocess, 405.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/Bildexport_2_resize.jpg\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/4_2_resize.png: 640x640 2 main_beams, 3 side_beams, 403.2ms\n",
      "Speed: 0.9ms preprocess, 403.2ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/4_2_resize.png\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/3_2_resize.png: 640x640 4 side_beams, 406.2ms\n",
      "Speed: 0.9ms preprocess, 406.2ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/3_2_resize.png\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/1_4_resize.png: 640x640 2 main_beams, 409.4ms\n",
      "Speed: 1.3ms preprocess, 409.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/1_4_resize.png\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/2_2_resize.png: 640x640 1 main_beam, 3 side_beams, 401.7ms\n",
      "Speed: 1.3ms preprocess, 401.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/2_2_resize.png\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/2_5_resize.png: 640x640 1 main_beam, 3 side_beams, 490.4ms\n",
      "Speed: 0.9ms preprocess, 490.4ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/2_5_resize.png\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/1_3_resize.png: 640x640 2 main_beams, 4 side_beams, 413.7ms\n",
      "Speed: 1.8ms preprocess, 413.7ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/1_3_resize.png\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/4_5_resize.png: 640x640 4 side_beams, 419.7ms\n",
      "Speed: 1.0ms preprocess, 419.7ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/4_5_resize.png\n",
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/Arbeiten/RAW-DATA/FARO_pano_pc/test/resized/3_5_resize.png: 640x640 1 main_beam, 5 side_beams, 418.0ms\n",
      "Speed: 0.9ms preprocess, 418.0ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Image saved: /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/tests/test_more/resized/3_5_resize.png\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO(model_path)\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "image_files = [os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith(('.jpg', '.jpeg', '.JPG', '.png', '.bmp'))]\n",
    "\n",
    "for img_path in image_files:\n",
    "    results = model.predict(img_path)\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    overlay = np.zeros_like(img)\n",
    "\n",
    "    for result in results:\n",
    "        if result.masks is not None:\n",
    "            for mask, box in zip(result.masks.xy, result.boxes):\n",
    "                random_color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "                \n",
    "                points = np.array([mask], dtype=np.int32) \n",
    "                cv2.fillPoly(overlay, points, random_color) \n",
    "                \n",
    "                confidence = box.conf[0]\n",
    "                if confidence > 0.4:\n",
    "                    xyxy = box.xyxy[0].cpu().numpy().astype(int)\n",
    "                    cv2.rectangle(img, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), random_color, 2)\n",
    "                    cv2.putText(img, confidence_text, (xyxy[0], xyxy[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, random_color, 2)\n",
    "\n",
    "    cv2.addWeighted(overlay, 0.4, img, 0.6, 0, img) \n",
    "\n",
    "    unique_save_path = os.path.join(save_path, os.path.basename(img_path))\n",
    "    cv2.imwrite(unique_save_path, img)\n",
    "    print(f\"Image saved: {unique_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/holmes/Documents/UNI-Bamberg/4.Semester_MA/Masterthesis/xAI_Masterthesis_Pan/Code/Segmentation/YOLO/YOLO-v8-seg/YOLO-seg-test-4/123/resized/Model_1_0009_jpeg.rf.56cf23d9b2a62e6a83c0d3fa545f5d55_resize.jpg: 640x640 1 main_beam, 1 side_beam, 439.3ms\n",
      "Speed: 1.3ms preprocess, 439.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Masks' object has no attribute 'dtype'. See valid attributes below.\n\n    A class for storing and manipulating detection masks.\n\n    Attributes:\n        xy (list): A list of segments in pixel coordinates.\n        xyn (list): A list of normalized segments.\n\n    Methods:\n        cpu(): Returns the masks tensor on CPU memory.\n        numpy(): Returns the masks tensor as a numpy array.\n        cuda(): Returns the masks tensor on GPU memory.\n        to(device, dtype): Returns the masks tensor with the specified device and dtype.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m mask_np \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(mask, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Convert boolean mask to uint8 if necessary\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask_np\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n\u001b[1;32m     42\u001b[0m     mask_np \u001b[38;5;241m=\u001b[39m mask_np\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m  \u001b[38;5;66;03m# Convert boolean mask to uint8\u001b[39;00m\n\u001b[1;32m     44\u001b[0m polygons \u001b[38;5;241m=\u001b[39m mask_to_polygons(mask_np)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.11/site-packages/ultralytics/utils/__init__.py:162\u001b[0m, in \u001b[0;36mSimpleClass.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. See valid attributes below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Masks' object has no attribute 'dtype'. See valid attributes below.\n\n    A class for storing and manipulating detection masks.\n\n    Attributes:\n        xy (list): A list of segments in pixel coordinates.\n        xyn (list): A list of normalized segments.\n\n    Methods:\n        cpu(): Returns the masks tensor on CPU memory.\n        numpy(): Returns the masks tensor as a numpy array.\n        cuda(): Returns the masks tensor on GPU memory.\n        to(device, dtype): Returns the masks tensor with the specified device and dtype.\n    "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def mask_to_polygons(mask):\n",
    "    # Ensure mask is a 2D numpy array of type uint8\n",
    "    if mask.ndim > 2:\n",
    "        mask = mask[:, :, 0]  # Assuming mask might be multi-channel\n",
    "    if mask.dtype != np.uint8:\n",
    "        mask = mask.astype(np.uint8)  # Convert mask to uint8\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    polygons = [contour.flatten().tolist() for contour in contours if len(contour) > 0]\n",
    "    return polygons\n",
    "\n",
    "model = YOLO(model_path)\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "image_files = [os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith(('.jpg', '.jpeg', '.JPG', '.png', '.bmp'))]\n",
    "\n",
    "for img_path in image_files:\n",
    "    results = model.predict(img_path)\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    overlay = np.zeros_like(img)\n",
    "    detection_results = []\n",
    "\n",
    "    for result in results:\n",
    "        masks = result.masks\n",
    "    for mask, box in zip(masks, result.boxes):\n",
    "        # Ensure mask is converted to numpy array and is on CPU\n",
    "        mask_np = mask.numpy() if hasattr(mask, 'numpy') else mask.to('cpu', dtype=torch.uint8).numpy()\n",
    "        \n",
    "        # Convert boolean mask to uint8 if necessary\n",
    "        if mask_np.dtype == np.bool_:\n",
    "            mask_np = mask_np.astype(np.uint8) * 255  # Convert boolean mask to uint8\n",
    "\n",
    "        polygons = mask_to_polygons(mask_np)\n",
    "\n",
    "            random_color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "            points = np.array([polygon for polygon in polygons], dtype=np.int32) if polygons else []\n",
    "            if points.size > 0:\n",
    "                cv2.fillPoly(overlay, points, random_color)\n",
    "            \n",
    "            confidence = box.conf[0]\n",
    "            if confidence > 0.4:\n",
    "                xyxy = box.xyxy[0].cpu().numpy().astype(int)\n",
    "                class_id = int(box.cls[0])\n",
    "                class_name = model.names[class_id]\n",
    "\n",
    "                detection_results.append({\n",
    "                    \"class_id\": class_id,\n",
    "                    \"class_name\": class_name,\n",
    "                    \"box\": xyxy.tolist(),\n",
    "                    \"score\": float(confidence),\n",
    "                    \"mask\": polygons\n",
    "                })\n",
    "\n",
    "                cv2.rectangle(img, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), random_color, 2)\n",
    "                cv2.putText(img, f\"{class_name} {confidence:.2f}\", (xyxy[0], xyxy[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, random_color, 2)\n",
    "\n",
    "    cv2.addWeighted(overlay, 0.4, img, 0.6, 0, img)\n",
    "    unique_save_path = os.path.join(save_path, os.path.basename(img_path))\n",
    "    cv2.imwrite(unique_save_path, img)\n",
    "    print(f\"Image saved: {unique_save_path}\")\n",
    "\n",
    "    # Save results to JSON\n",
    "    json_file_path = os.path.join(save_path, os.path.splitext(os.path.basename(img_path))[0] + \".json\")\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        json.dump({\"file_name\": os.path.basename(img_path), \"instances\": detection_results}, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
